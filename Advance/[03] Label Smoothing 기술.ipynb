{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advance 자료 3: Label Smoothing\n",
    "\n",
    "`Label Smoothing (LS)`은 이미지 분류뿐만 아니라 다른 언어 번역등의 기술에서 많이 사용되는 기술입니다.\n",
    "\n",
    "`LS`는 앞선 기술과 달리 image를 augmentation하는 기술이 아닌, label을 변환시키는 기술입니다.\n",
    "\n",
    "`LS`는 말 그대로 label을 스무딩하여 모델 일반화 성능을 향상시킵니다.\n",
    "\n",
    "Hard target(one-hot-representation)을 soft target으로 바꾸는 것이 핵심입니다. 여기서의 hard target은 one-hot vector로 $[0,1,0,0]$의 형태를 말합니다.\n",
    "\n",
    "K 개 범주(class)에 관한 레이블 스무딩 벡터의  k 번째 스칼라(sclar) 값은 다음 수식과 같습니다( yk 는  k 번째 범주가 정답이면 1, 그렇지 않으면 0,  α 는 hyperparameter).\n",
    "\n",
    "$$ y^{LS}_k = (1-\\alpha) y_k + \\alpha / K$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "from torch import cuda, nn, optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    # Label smoothing method: https://arxiv.org/abs/1512.00567\n",
    "    # It injects the uniform noise to the hard target (i.e., one-hot vector) whose magnitude is epsilon.\n",
    "    def __init__(self, device, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = ?????????\n",
    "            ??????????????\n",
    "            ??????????????\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(images, labels, device, alpha=1.0):\n",
    "    \"\"\"\n",
    "    mixup function from 'mixup: BEYOND EMPIRICAL RISK MINIMIZATION', \n",
    "    https://arxiv.org/pdf/1710.09412.pdf\n",
    "    \"\"\"\n",
    "        \n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(images.size()[0]).to(device)\n",
    "    labels1 = labels\n",
    "    labels2 = labels[rand_index]\n",
    "    images2 = copy.deepcopy(images)\n",
    "            \n",
    "    images = Variable(lam * images + (1-lam)*images2[rand_index,:,:,:]).to(device)\n",
    "    \n",
    "    return lam, images, labels1, labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix(images, labels, device, alpha = 1.0):\n",
    "    \"\"\"\n",
    "    cutmix function from 'CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features',\n",
    "    https://arxiv.org/abs/1905.04899\n",
    "    \"\"\"\n",
    "    \n",
    "    #generate mixed sample\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rand_index = torch.randperm(images.size()[0]).to(device)\n",
    "    labels_a = labels\n",
    "    labels_b = labels[rand_index]\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n",
    "    images[:, :, bbx1:bbx2, bby1:bby2] = images[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "    #adjust lambda to exactly match pixel ratio\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n",
    "    #compute output\n",
    "    images = torch.autograd.Variable(images, requires_grad=True).to(device)\n",
    "\n",
    "    return lam, images, labels_a, labels_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "device = 'cuda:0'\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v2(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, len(classes))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-5)\n",
    "scheduler = lr_scheduler.MultiStepLR(gamma=0.1, milestones=[10, 15], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    batch_size = target.size(0)\n",
    "    num = output.size(1)\n",
    "    target_topk = []\n",
    "    appendices = []\n",
    "    for k in topk:\n",
    "        if k <= num:\n",
    "            target_topk.append(k)\n",
    "        else:\n",
    "            appendices.append([0.0])\n",
    "    topk = target_topk\n",
    "    maxk = max(topk)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res + appendices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, trainloader, testloader, device, num_epochs, reg):\n",
    "    state = {}\n",
    "    current_state = copy.deepcopy(model.state_dict())\n",
    "    for k, v in current_state.items():\n",
    "        current_state[k] = v.cpu()\n",
    "    state['init'] = copy.deepcopy(current_state)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        scheduler.step()\n",
    "        \n",
    "        losses = []\n",
    "        for i, (images, labels) in enumerate(tqdm(trainloader)):\n",
    "            images = images.type(torch.FloatTensor).to(device)\n",
    "            labels = labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "            if reg in ['cutmix', 'mixup']:\n",
    "                if reg == 'cutmix':\n",
    "                    lam, images, labels_a, labels_b = cutmix(images, labels, device)\n",
    "                elif reg == 'mixup':\n",
    "                    lam, images, labels_a, labels_b = mixup(images, labels, device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                ???????????????????????\n",
    "            elif reg == 'ls':\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = ????????????????????????\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print('[epoch: %d] train loss: %.3f' %\n",
    "                  (epoch + 1, np.mean(losses)))\n",
    "        tl, ta = eval_model(model, testloader, nn.CrossEntropyLoss(), device)\n",
    "        print('[epoch: %d] test loss: %.3f, test accuracy: %.4f' %\n",
    "                  (epoch + 1, tl, ta))\n",
    "        if epoch == num_epochs-1:\n",
    "            current_state = copy.deepcopy(model.state_dict())\n",
    "            for k, v in current_state.items():\n",
    "                current_state[k] = v.cpu()\n",
    "            state[str(epoch)] = copy.deepcopy(current_state)\n",
    "    \n",
    "    torch.save(state, 'practice.t1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for i, data in enumerate(loader):\n",
    "        image = data[0].type(torch.FloatTensor).to(device)\n",
    "        label = data[1].type(torch.LongTensor).to(device)\n",
    "        \n",
    "        pred_label = model(image)\n",
    "\n",
    "        loss = criterion(pred_label, label)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if i == 0:\n",
    "            labels = label.cpu().detach().numpy()\n",
    "            pred_labels = pred_label.cpu().detach().numpy()\n",
    "        else:\n",
    "            labels = np.concatenate((labels, label.cpu().detach().numpy()), axis=0, out=None)\n",
    "            pred_labels = np.concatenate((pred_labels, pred_label.cpu().detach().numpy()), axis=0, out=None)\n",
    "            \n",
    "        image = image.cpu()\n",
    "        label = label.cpu()\n",
    "        with torch.cuda.device(device):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    pred_labels = np.argmax(pred_labels, axis=1)\n",
    "    return np.mean(losses), np.sum(pred_labels==labels)/float(labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:29<00:00, 26.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1] train loss: 1.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch: 1] test loss: 1.978, test accuracy: 0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 272/782 [00:10<00:19, 26.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-0307d2219ffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-52392759a627>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, trainloader, testloader, device, num_epochs, reg)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, scheduler, trainloader, testloader, device, num_epochs, 'none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### <프로젝트>\n",
    "\n",
    "- Image Classification의 성능을 보았습니다.\n",
    "\n",
    "- 이것의 learning rate, optimizer, scheduler, mixup, cutmix, label smoothing 등을 이리 저리 활용하여서 신경망의 성능을 올리세요.\n",
    "\n",
    "- num_epoch은 20번 이내로 사용하실 수 있습니다.\n",
    "\n",
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
