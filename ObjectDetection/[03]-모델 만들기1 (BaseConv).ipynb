{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [03] 모델 만들기1 - BaseConv\n",
    "\n",
    "우리가 만들고자 하는 객체 검출기(Object Detector)는 3개의 부분으로 구성됩니다. 각 모듈들의 역할은 다음과 같습니다.\n",
    "\n",
    "- BaseConv: 이미지 데이터의 특징(Feature)을 추출\n",
    "- AuxConv: BaseConv로부터의 특징을 다양한 스케일로 학습\n",
    "- PredConv: 특징들을 기반으로 Bounding Box와 ClassScore를 예측\n",
    "\n",
    "먼저, 첫번째 모듈인 `BaseConv`를 만들어 보겠습니다. BaseConv에는 여러 CNN 아키텍쳐(VGG, ResNet, DenseNet, Wide-ResNet, MobileNet ... 등)를 사용할 수 있지만, 이번 실습에서는 모델의 크기와 연산량 면에서 효율적인 EfficientNet을 활용해 보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "EfficientNet은 MobileNet구조를 기반으로 아키텍쳐를 탐색한 다음, Width, Depth, Resolution을 복합적으로 고려해 모델을 Scaling했을 때, 큰 성능 향상을 기대할 수 있다는 것을 제안하였습니다. \n",
    "\n",
    "- 아래는 EfficientNet의 Compund Scaling 기법과 성능에 대해 나타내고 있습니다. 더블클릭을 통해 확대해 살펴보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td><img src='img/[03]eff_arch.png'></td><td><img src='img/[03]eff_perf.png'></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Images from https://arxiv.org/abs/1905.11946\n",
    "display(HTML(\"<table><tr><td><img src='img/[03]eff_arch.png'></td><td><img src='img/[03]eff_perf.png'></td></tr></table>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## [Task 1] Pre-trained EfficientNet\n",
    "\n",
    "`materials.models`에 EfficientNet의 코드가 있습니다. 이 코드를 활용하여, ImageNet에 대해 pre-trained된 EfficientNet-b0의 weight를 가져오도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from materials.models.EfficientNet import EfficientNet\n",
    "from materials.utils import *\n",
    "\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "# 아래 주석을 해제하여 efficientnet-bo의 구조를 살펴보세요!\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원래의 모델은 imagenet 1000개의 class에 대한 예측치를 출력하도록 학습되었지만, Object Detection을 위해서는 예측치 대신 다양한 크기의 featuremap이 필요하기 때문에 16개의 block중에서 11번째, 16번째 block에서의 featuremap을 리턴하도록 바꾸어 놓은 상태입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo: 모델의 출력값 확인하기\n",
    "\n",
    "우리가 사용할 300x300의 이미지에 대하여 모델이 어떤 형태의 출력값을 가지는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 리턴값의 Shape: torch.Size([4, 112, 18, 18])\n",
      "2번째 리턴값의 Shape: torch.Size([4, 1280, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "# [ToDo]: 300 * 300 의 random tensor를 모델에 입력해 결과를 출력합니다.\n",
    "sample = ??????????????????\n",
    "outputs = model(sample)\n",
    "\n",
    "for i, out in enumerate(outputs):\n",
    "    print('{}번째 리턴값의 Shape: {}'.format(i+1, out.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## [Task 2] Selectively Freeze Layers\n",
    "\n",
    "학습된 weights를 최대한 활용하기 위해서, pre-trained model의 weight를 학습이 되지 않는 상태로 만들고자 합니다. \n",
    "\n",
    "그러나 학습 도메인의 데이터 또한 모델이 충분히 학습할 수 있기를 기대하기 때문에, 모델의 일부는 학습이 가능한 형태로 남겨두고 싶습니다.\n",
    "\n",
    "### ToDo: Freeze / Unfreeze Layers\n",
    "\n",
    "- 모델 전체를 학습이 되지 않도록 설정합니다.\n",
    "- 모델의 block15의 parameter를 학습가능하도록 설정합니다. (_block15)\n",
    "- 모델의 convhead의 parameter를 학습가능하도록 설정합니다. (_convhead)\n",
    "- 모델의 마지막 batchnorm 층의 parameter를 학습가능하도록 설정합니다. (_bn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "\n",
    "# [ToDo]: 모델의 모든 Parameter를 학습되지 않도록 설정합니다.\n",
    "for params in model.parameters():\n",
    "    params.?????????? = ???????\n",
    "    \n",
    "# [ToDo]: block15의 parameter와 convhead의 parameter는 학습이 가능하도록 합니다.\n",
    "for name, params in model.named_parameters():\n",
    "    if str(15) in str(name):\n",
    "        params.requires_grad = True\n",
    "            \n",
    "    if 'head' in str(name):\n",
    "        params.requires_grad = True\n",
    "        \n",
    "    if '_bn1' in  str(name):\n",
    "        params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint : 모델의 parameter들에는 이름이 있습니다!\n",
    "#for name, params in model.named_parameters():\n",
    "#    param_names.append(name)\n",
    "#    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## [Task 3] BaseConvluition Class\n",
    "\n",
    "Task1, Task2를 통해 객체 검출(Object Detection)을 위한 특징 추출기(feature extractor)를 만들었습니다. 지금까지의 과정을 통합하여 pytorch의 `nn.module` Class를 상속하는 하나의 Neural Network 모델로 구성해 봅시다.\n",
    "\n",
    "### ToDo: nn.Module Class로 통합하기\n",
    "\n",
    "- `__init__()` 함수를 완성합니다.\n",
    "- `forward` 함수를 완성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from materials.models.EfficientNet import EfficientNet\n",
    "\n",
    "class BaseConvolution(nn.Module):\n",
    "    def __init__(self, unfreeze_keys=['15', 'head', 'bn1']):\n",
    "        \"\"\"\n",
    "        Pre-trained EfficientNet을 불러와 BaseConv를 구성합니다,\n",
    "        \"\"\"        \n",
    "        super(BaseConvolution, self).__init__()\n",
    "        self.base = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        \n",
    "        # 모델의 모든 parameter를 학습이 되지 않도록 합니다.\n",
    "        for params in self.base.parameters():\n",
    "            params.requires_grad = False\n",
    "        \n",
    "        # [ToDo]: `unfreeze_keys`에 해당하는 parameter는 학습이 가능하도록 합니다.\n",
    "        for name, params in self.base.named_parameters():\n",
    "            for key in ????????????:\n",
    "                if key in ???????????:\n",
    "                    params.??????????? = ?????????\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        BaseConvolution을 통과하여 나온 3개의 featuremap을 리턴합니다. \n",
    "        (tensor) x: (N, C, H, W)의 Image Data.\n",
    "        \"\"\"\n",
    "        # base conv 연산을 수행합니다.\n",
    "        mid, end = self.base(x)\n",
    "        \n",
    "        return mid, end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      "mid shape torch.Size([4, 112, 18, 18])\n",
      "end shape torch.Size([4, 1280, 9, 9])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BaseConvolution Class를 테스트합니다.\n",
    "baseconv = BaseConvolution()\n",
    "\n",
    "sample = torch.randn(4, 3, 300, 300)\n",
    "mid, end = baseconv(sample)\n",
    "\n",
    "print('\\nmid shape {}'.format(mid.shape))\n",
    "print('end shape {}\\n'.format(end.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### <생각해 봅시다>\n",
    "\n",
    "- Feature map을 몇 번째 block에서 뽑는지는 어떤 영향을 미칠까요?\n",
    "- Pre-trained model의 freeze/unfreeze의 여부를 어떻게 정해야 할까요?\n",
    "\n",
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
