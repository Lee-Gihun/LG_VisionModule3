{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [08] 손실함수 설정하기\n",
    "\n",
    "데이터로부터의 예측을 바탕으로 라벨과 비교하여 모델을 학습하는 방법을 지도학습(Supervised Learning)이라고 합니다. 지도학습에서는 라벨과 예측을 어떻게 비교할지를 손실함수(Loss Function)을 통해 명확히 정의해야 합니다. 객체인식(Object Detection)에서의 손실함수를 설정하는 것은 다음의 이유로 상당히 까다롭습니다.\n",
    "- 1) 모델이 아주 많은 수의 Box를 예측하고 있고 이를 Bounding Box, Class 정보와 매칭시켜 Loss를 정해줘야 함.\n",
    "- 2) Bounding Box를 잘 잡는 (Location) 것과 Class를 잘 예측하는 (Class Score) 두 가지에 대해 조화롭게 학습해야 함.\n",
    "\n",
    "다행히, 이전 실습에서 만들었던 Prior Box들을 활용하여 문제의 구조를 손실함수를 계산하기 용이하게 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='img/[08]loss1.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Image from c231n Lecture Note\n",
    "display(HTML(\"<img src='img/[08]loss1.png'>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Batch Shape: torch.Size([8, 3, 300, 300])\n",
      "Boxes Batch Length: 8\n",
      "Labels Batch Length: 8\n",
      "Loaded pretrained weights for efficientnet-b0\n",
      "\n",
      ">>> Location 예측의 Shape: torch.Size([8, 3106, 4])\n",
      ">>> Clsss Score 예측의 Shape: torch.Size([8, 3106, 20])\n",
      "\n",
      ">>> Prior Boxes의 Shape: torch.Size([3106, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from materials.DetectionNet import DetectionNet, create_prior_boxes\n",
    "from materials.datasets import PascalVOCDataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = PascalVOCDataset(data_folder='./data/VOC', split='TRAIN')\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=8, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
    "images, boxes, labels, difficulties = next(iter(train_dataloader))\n",
    "\n",
    "images = images.to(device)\n",
    "boxes = [b.to(device) for b in boxes]\n",
    "labels = [l.to(device) for l in labels]\n",
    "\n",
    "print('\\nImage Batch Shape: {}'.format(images.shape))\n",
    "print('Boxes Batch Length: {}'.format(len(boxes)))\n",
    "print('Labels Batch Length: {}'.format(len(labels)))\n",
    "\n",
    "net = DetectionNet(n_classes=20, unfreeze_keys='all').to(device)\n",
    "pred_locs, pred_scores = net(images)\n",
    "\n",
    "print('\\n>>> Location 예측의 Shape: {}'.format(pred_locs.shape))\n",
    "print('>>> Clsss Score 예측의 Shape: {}'.format(pred_scores.shape))\n",
    "\n",
    "prior_boxes = create_prior_boxes()\n",
    "print('\\n>>> Prior Boxes의 Shape: {}'.format(prior_boxes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## [Task 1] GroundTruth Boxes 만들기 + Location Loss\n",
    "Prior Boxes들에 대해 정답(box 좌표 및 라벨)을 설정하고, 우리가 예측한 Box들이 해당 정답들을 따라가도록 학습하는 방식을 통해 학습을 할 수 있습니다. Prior Box에 대해 1:1로 정답 Box (그리고 Label)을 지정해 주는 것입니다.\n",
    "\n",
    "- Box 좌표 : 정답 Box 좌표에 대해 Regression\n",
    "- Box 라벨 : 정답 Label에 대해 Cross-Entropy Loss\n",
    "\n",
    "### ToDo: `create_prior_boxes` 함수 완성하기\n",
    "\n",
    "주어진 값들을 바탕으로 GT prior box들을 만들어 봅니다.\n",
    "\n",
    "### ToDo: Location Loss 계산하기\n",
    "\n",
    "GT prior box를 사용하여 Location Loss를 계산해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from materials.utils import *\n",
    "\n",
    "batch_size, num_classes = 8, 20\n",
    "n_priors = prior_boxes.size(0)\n",
    "\n",
    "# piror를 cxcy, xy 두 종류의 좌표로 저장합니다.\n",
    "priors_cxcy = prior_boxes\n",
    "priors_xy = cxcy_to_xy(prior_boxes)\n",
    "\n",
    "# Prior Boxes의 개수가 Prediction Boxes의 개수와 같아야 합니다. (3106개)\n",
    "assert n_priors == pred_locs.size(1) == pred_scores.size(1)\n",
    "\n",
    "# Prior Boxes에 GroundTruth 정보를 할당하기 위한 Tensor를 만듭니다.\n",
    "true_locs = torch.zeros((batch_size, n_priors, 4), dtype=torch.float).to(device) # (N, 3106, 4)\n",
    "true_classes = torch.zeros((batch_size, n_priors), dtype=torch.long).to(device) # (N, 3106)\n",
    "\n",
    "# Batch 안의 각 Image에 대해\n",
    "for i in range(batch_size):\n",
    "    n_objects = boxes[i].size(0) # Label에 존재하는 Object의 개수\n",
    "    \n",
    "    # GT Boxes와 Prior Boxes의 Jaccard Overlap을 계산합니다.\n",
    "    overlap = find_jaccard_overlap(boxes[i], priors_xy) # (n_objects, 3106)\n",
    "    \n",
    "    # [ToDo]: 각 prior box에 가장 높은 overlap을 가지는 object에 대한 (overlap값, object idx)를 구합니다.\n",
    "    overlap_for_each_prior, object_for_each_prior = ?????????????? # (3106) (3106)\n",
    "    \n",
    "    # [ToDo]: 각 obejct와 가장 높은 overlap을 가지는 box의 idx를 찾습니다.\n",
    "    _, prior_for_each_object = ???????????? # (n_objects, )\n",
    "    \n",
    "    # 각 object들을 가장 높은 overlap을 가지는 prior에 할당합니다.\n",
    "    # 이 object들에는 overlap값을 1로 바꿔줍니다.\n",
    "    object_for_each_prior[prior_for_each_object] = torch.LongTensor(range(n_objects)).to(device)\n",
    "    overlap_for_each_prior[prior_for_each_object] = 1.\n",
    "    \n",
    "    # prior에 대해 class label을 할당합니다.\n",
    "    label_for_each_prior = labels[i][object_for_each_prior]  # (3106)\n",
    "    \n",
    "    # [ToDo] : overlap이 threshold(0.5) 미만이면 라벨을 0(background)으로 설정합니다.\n",
    "    label_for_each_prior[?????????????????] = ?  # (3106)\n",
    "\n",
    "    # true class 정보를 저장합니다.\n",
    "    true_classes[i] = label_for_each_prior\n",
    "\n",
    "    # regression을 위한 좌표로 바꾸어 true box 좌표 정보를 저장합니다.\n",
    "    true_locs[i] = cxcy_to_gcxgcy(xy_to_cxcy(boxes[i][object_for_each_prior]), prior_boxes)  # (3106, 4)\n",
    "\n",
    "# Positivie(class 라벨이 1~20중 하나로 존재), Negative prior(background)에 대한 mask를 얻습니다.\n",
    "positive_priors = true_classes != 0 # (N, 3106)\n",
    "negative_priors = true_classes == 0 # (N, 3106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch에 있는 8개 이미지 데이터에 대한 Positive Prior의 개수:\n",
      "[28, 18, 13, 29, 12, 25, 4, 15]\n",
      "\n",
      "Batch에 있는 n8개 이미지 데이터에 대한 Negative Prior의 개수:\n",
      "[3078, 3088, 3093, 3077, 3094, 3081, 3102, 3091]\n"
     ]
    }
   ],
   "source": [
    "print('Batch에 있는 8개 이미지 데이터에 대한 Positive Prior의 개수:')\n",
    "print(positive_priors.sum(dim=1).tolist())\n",
    "\n",
    "print('\\nBatch에 있는 n8개 이미지 데이터에 대한 Negative Prior의 개수:')\n",
    "print(negative_priors.sum(dim=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location Loss: 3.5385\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Location Loss를 L1로 지정합니다.\n",
    "smooth_l1 = nn.L1Loss()\n",
    "\n",
    "# [ToDo] : pred_locs와 true_locs의 positivie값들에 대해 Location Loss를 연산합니다. \n",
    "loc_loss = smooth_l1(??????????????????, ??????????????????)  # (), scalar\n",
    "\n",
    "print('Location Loss: %3.4f' % loc_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## [Task 2] Confidence Loss 만들기\n",
    "Prior Boxes(Ground Truth)와 Pred Boxes의 라벨을 비교하여 정답 라벨을 맞출 수 있도록 학습하는 Confidence Loss를 만들어 보도록 하겠습니다. 이번에는 Location Loss처럼 Positivive만 비교하지 않고 Negative Prior도 함께 사용하여 Background에 해당하는 Box도 걸러낼 수 있도록 하고 싶습니다. 그러나 Negative Prior의 개수는 Positive보다 훨씬 많기 때문에, 이 중에서 학습에서 효과적으로 활용할 수 있는 Negative Prior들을 `Hard Negative Mining`을 통해 뽑아서 사용합니다.\n",
    "\n",
    "- Hard Negative Mining\n",
    "많은 Negative 중에서 어려운 Negative들만을 뽑아서 사용함으로써 Negative에 대한 학습을 효과적으로 수행합니다. 이번에는 Negative Prior중에서 **\"Loss가 큰 순서대로 정렬하여 Negative를 Positive의 3배 만큼의 개수만 반영\"** 하는 방식으로 Hard Negative Mining을 해보겠습니다.\n",
    "\n",
    "### ToDo: Hard Negatvie Mining + Confidence Loss 계산하기\n",
    "- Hard Negative Prior에 대한 Loss만 반영하여 Confidence Loss를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24848])\n"
     ]
    }
   ],
   "source": [
    "# CONFIDENCE LOSS를 계산하기 위한 CrossEntropyLoss를 선언합니다.\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "n_classes = 20\n",
    "neg_pos_ratio = 3\n",
    "\n",
    "# image당 hard_negative로 삼을 prior의 개수를 계산합니다.\n",
    "n_positives = positive_priors.sum(dim=1)  # (N)\n",
    "n_hard_negatives = neg_pos_ratio * n_positives  # (N)\n",
    "\n",
    "# 모든 prior에 대한 loss를 계산합니다.\n",
    "conf_loss_all = criterion(pred_scores.view(-1, n_classes), true_classes.view(-1))  # (N * 3106)\n",
    "conf_loss_all = conf_loss_all.view(batch_size, n_priors)  # (N, 3106)\n",
    "\n",
    "# Negative Prior에 대해 confidence loss를 저장할 tensor를 따로 만듭니다.\n",
    "conf_loss_neg = conf_loss_all.clone()  # (N, 3106)\n",
    "conf_loss_neg[positive_priors] = 0.  # (N, 3106), positive priors 는 고려하지 않을 것이므로 0을 할당.\n",
    "\n",
    "# [ToDo]: Loss를 기준으로 Negatvie prior들을 sorting합니다. \n",
    "conf_loss_neg, _ = ?????????????.sort(dim=????, descending=????)  # (N, 3106), 난이도(loss의 크기)에 따라 sorting\n",
    "\n",
    "# 가장 큰 n_hard_negatives 개의 prior를 뽑습니다.\n",
    "hardness_ranks = torch.LongTensor(range(n_priors)).unsqueeze(0).expand_as(conf_loss_neg).to(device)  # (N, 3106)\n",
    "hard_negatives = hardness_ranks < n_hard_negatives.unsqueeze(1)  # (N, 3106)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo: Hard Negatvie Mining + Confidence Loss 계산하기\n",
    "- positivie, negative 각각에 대한 confidence loss를 구하고, 아래의 수식대로 적용해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='img/[08]loss2.jpg'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Image from https://arxiv.org/pdf/1512.02325.pdf\n",
    "display(HTML(\"<img src='img/[08]loss2.jpg'>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Loss: 91.3023\n",
      "\n",
      "Final Loss: 94.8408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [ToDo]: positivie prior에 대한 cofidence loss를 가져옵니다.\n",
    "conf_loss_pos = ???????????????????????  # (sum(n_positives))\n",
    "\n",
    "# [ToDo]: hard negative prior에 대한 confidence loss를 가져옵니다.\n",
    "conf_loss_hard_neg = ?????????????????  # (sum(n_hard_negatives))\n",
    "\n",
    "# Confidence Loss를 계산합니다.\n",
    "conf_loss = (conf_loss_hard_neg.sum() + conf_loss_pos.sum()) / n_positives.sum().float()  # (), scalar\n",
    "\n",
    "print('Confidence Loss: %3.4f\\n' % conf_loss.item())\n",
    "\n",
    "# Location Loss와 Confidence Loss를 더해 최종 Loss를 만듭니다.\n",
    "final_loss = loc_loss + conf_loss\n",
    "print('Final Loss: %3.4f\\n' % final_loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## MultiBox Loss\n",
    "아래에는 앞서 구성했던 Location Loss와 Cofidence Loss를 더해 MultiBox Loss로 연산하는 과정을 `nn.Module` class로 표현되어 있습니다. `MultiBoxLoss`는 이미 완성되어 있습니다. class를 통해 연산하고 이전의 결과값과 비교해 봅시다.\n",
    "\n",
    "### ToDo: MultiboxLoss로 연산하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from materials.utils import *\n",
    "\n",
    "class MultiBoxLoss(nn.Module):\n",
    "    def __init__(self, priors_cxcy, threshold=0.5, neg_pos_ratio=3, alpha=1.):\n",
    "        super(MultiBoxLoss, self).__init__()\n",
    "        self.priors_cxcy = priors_cxcy\n",
    "        self.priors_xy = cxcy_to_xy(priors_cxcy)\n",
    "        self.threshold = threshold\n",
    "        self.neg_pos_ratio = neg_pos_ratio\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.smooth_l1 = nn.L1Loss()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, predicted_locs, predicted_scores, boxes, labels):\n",
    "        batch_size = predicted_locs.size(0)\n",
    "        n_priors = self.priors_cxcy.size(0)\n",
    "        n_classes = predicted_scores.size(2)\n",
    "\n",
    "        assert n_priors == predicted_locs.size(1) == predicted_scores.size(1)\n",
    "\n",
    "        true_locs = torch.zeros((batch_size, n_priors, 4), dtype=torch.float).to(device)\n",
    "        true_classes = torch.zeros((batch_size, n_priors), dtype=torch.long).to(device)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            n_objects = boxes[i].size(0)\n",
    "\n",
    "            overlap = find_jaccard_overlap(boxes[i], self.priors_xy)\n",
    "\n",
    "            overlap_for_each_prior, object_for_each_prior = overlap.max(dim=0)\n",
    "\n",
    "            _, prior_for_each_object = overlap.max(dim=1)\n",
    "\n",
    "            object_for_each_prior[prior_for_each_object] = torch.LongTensor(range(n_objects)).to(device)\n",
    "            overlap_for_each_prior[prior_for_each_object] = 1.\n",
    "\n",
    "            label_for_each_prior = labels[i][object_for_each_prior]  # (8732)\n",
    "            label_for_each_prior[overlap_for_each_prior < self.threshold] = 0  # (8732)\n",
    "\n",
    "            true_classes[i] = label_for_each_prior\n",
    "            true_locs[i] = cxcy_to_gcxgcy(xy_to_cxcy(boxes[i][object_for_each_prior]), self.priors_cxcy)  # (8732, 4)\n",
    "\n",
    "        positive_priors = true_classes != 0\n",
    "\n",
    "        # LOCALIZATION LOSS\n",
    "        loc_loss = self.smooth_l1(predicted_locs[positive_priors], true_locs[positive_priors])\n",
    "        n_positives = positive_priors.sum(dim=1)\n",
    "        n_hard_negatives = self.neg_pos_ratio * n_positives \n",
    "        \n",
    "        # CONFIDENCE LOSS\n",
    "        conf_loss_all = self.cross_entropy(predicted_scores.view(-1, n_classes), true_classes.view(-1))\n",
    "        conf_loss_all = conf_loss_all.view(batch_size, n_priors)\n",
    "\n",
    "        conf_loss_pos = conf_loss_all[positive_priors]  # (sum(n_positives))\n",
    "\n",
    "        conf_loss_neg = conf_loss_all.clone()  # (N, 8732)\n",
    "        conf_loss_neg[positive_priors] = 0.  # (N, 8732), positive priors are ignored (never in top n_hard_negatives)\n",
    "        conf_loss_neg, _ = conf_loss_neg.sort(dim=1, descending=True)  # (N, 8732), sorted by decreasing hardness\n",
    "        hardness_ranks = torch.LongTensor(range(n_priors)).unsqueeze(0).expand_as(conf_loss_neg).to(device)  # (N, 8732)\n",
    "        hard_negatives = hardness_ranks < n_hard_negatives.unsqueeze(1)  # (N, 8732)\n",
    "        conf_loss_hard_neg = conf_loss_neg[hard_negatives]  # (sum(n_hard_negatives))\n",
    "\n",
    "        conf_loss = (conf_loss_hard_neg.sum() + conf_loss_pos.sum()) / n_positives.sum().float()  # (), scalar\n",
    "\n",
    "        # TOTAL LOSS\n",
    "        return conf_loss + self.alpha * loc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ToDo]: MultiBoxLoss 선언하기\n",
    "criterion = MultiBoxLoss(priors_cxcy=prior_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multibox Loss: 94.8408\n"
     ]
    }
   ],
   "source": [
    "boxes = [b.to(device) for b in boxes]\n",
    "labels = [l.to(device) for l in labels]\n",
    "\n",
    "# [ToDo]: MultiboxLoss 연산하기\n",
    "loss = criterion(pred_locs, pred_scores, boxes, labels)\n",
    "\n",
    "print('Multibox Loss: %3.4f' % loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### <생각해 봅시다>\n",
    "\n",
    "- Hard Negative Mining의 역할은 무엇인가요?\n",
    "- Positivie/Negative를 나누는 Overlap의 Threshold는 어떤 의미를 갖나요?\n",
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
