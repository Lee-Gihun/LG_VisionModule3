{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [09] 모델 학습하기\n",
    "\n",
    "데이터, 라벨, 모델, 손실함수가 모두 준비되었기에 모델을 학습할 수 있게 되었습니다. 모델을 학습하기 위해서 우리든 다음의 요소들을 정의합니다.\n",
    "\n",
    "- Dataloader\n",
    "- Model\n",
    "- Criterion\n",
    "- Optimizer\n",
    "- Scheduler\n",
    "\n",
    "이외에 학습을 위해서 다양한 Hyperparameter들을 설정해야 합니다. 아래의 그림을 통해 Batch와 Epoch, Iteration에 대한 개념을 정리하고 설정된 학습 요소들을 살펴봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='img/[09]epoch.png'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "# Image from https://www.slideshare.net/w0ong/ss-82372826\n",
    "display(HTML(\"<img src='img/[09]epoch.png'>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "import torch, time\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "\n",
    "from materials.DetectionNet import DetectionNet, create_prior_boxes\n",
    "from materials.MultiboxLoss import MultiBoxLoss\n",
    "from materials.datasets import PascalVOCDataset\n",
    "from materials.utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = PascalVOCDataset(data_folder='./data/VOC', split='TRAIN')\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=8, shuffle=True, \n",
    "                              collate_fn=dataset.collate_fn, num_workers=4)\n",
    "\n",
    "model = DetectionNet(n_classes=21, unfreeze_keys=['15', 'head', 'bn1'], use_bias=True).to(device)\n",
    "criterion = MultiBoxLoss(priors_cxcy=create_prior_boxes(), threshold=0.5, neg_pos_ratio=0.3, alpha=1.0)\n",
    "\n",
    "num_epochs = 20\n",
    "lr, momentum, weight_decay = 1e-3, 0.9, 5e-4\n",
    "\n",
    "biases, not_biases = [], []\n",
    "\n",
    "for param_name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        if param_name.endswith('.bias'):\n",
    "            biases.append(param)\n",
    "        else:\n",
    "            not_biases.append(param)\n",
    "optimizer = torch.optim.SGD(params=[{'params': biases, 'lr': 2 * lr}, {'params': not_biases}],\n",
    "                            lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=False)\n",
    "scheduler = scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.00005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## [Task 1] Training Loop 만들기\n",
    "Training 과정에서 Batch마다, Epoch마다 어떠한 동작을 수행하는지를 지정함으로써 학습이 진행되도록 만들어 봅시다.\n",
    "\n",
    "### ToDo: `train` 함수 완성하기\n",
    "\n",
    "train 함수를 완성하고 학습을 시작해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, scheduler=None, \n",
    "          num_epochs=200, grad_clip=None, print_freq=1, \n",
    "          save_name='test', device=device):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        batch_time, data_time, losses = AverageMeter(), AverageMeter(), AverageMeter()\n",
    "        start = time.time()\n",
    "    \n",
    "        for i, (images, boxes, labels, _) in enumerate(dataloader):\n",
    "            data_time.update(time.time()-start)\n",
    "\n",
    "            images = images.to(device)\n",
    "            boxes = [b.to(device) for b in boxes]\n",
    "            labels = [l.to(device) for l in labels]\n",
    "\n",
    "            # forward pass\n",
    "            pred_locs, pred_scores = model(images)\n",
    "            loss = criterion(pred_locs, pred_scores, boxes, labels)\n",
    "            if loss > 100:\n",
    "                continue\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip is not None:\n",
    "                clip_gradient(optimizer, grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            batch_time.update(time.time() - start)\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            # Print status\n",
    "            if i % print_freq == 0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                      'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Data Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch, i, len(dataloader),\n",
    "                                                                      batch_time=batch_time,\n",
    "                                                                      data_time=data_time, loss=losses))\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "            \n",
    "    torch.save(model.state_dict(), './{}_{}.pth'.format(save_name, round(losses.val, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/2069]\tBatch Time 0.943 (0.943)\tData Time 0.613 (0.613)\tLoss 22.7096 (22.7096)\t\n",
      "Epoch: [0][50/2069]\tBatch Time 0.113 (0.094)\tData Time 0.050 (0.024)\tLoss 13.7948 (15.6236)\t\n",
      "Epoch: [0][100/2069]\tBatch Time 0.073 (0.085)\tData Time 0.011 (0.018)\tLoss 11.9240 (13.8904)\t\n",
      "Epoch: [0][150/2069]\tBatch Time 0.066 (0.082)\tData Time 0.001 (0.016)\tLoss 7.7615 (12.8175)\t\n",
      "Epoch: [0][200/2069]\tBatch Time 0.088 (0.081)\tData Time 0.028 (0.015)\tLoss 10.8786 (12.3814)\t\n",
      "Epoch: [0][250/2069]\tBatch Time 0.095 (0.081)\tData Time 0.029 (0.015)\tLoss 10.4246 (11.9725)\t\n",
      "Epoch: [0][300/2069]\tBatch Time 0.093 (0.080)\tData Time 0.027 (0.014)\tLoss 10.7510 (11.6937)\t\n",
      "Epoch: [0][350/2069]\tBatch Time 0.089 (0.080)\tData Time 0.025 (0.014)\tLoss 9.9810 (11.4010)\t\n",
      "Epoch: [0][400/2069]\tBatch Time 0.080 (0.079)\tData Time 0.013 (0.014)\tLoss 8.0719 (11.0602)\t\n",
      "Epoch: [0][450/2069]\tBatch Time 0.069 (0.078)\tData Time 0.001 (0.013)\tLoss 7.0713 (10.8552)\t\n",
      "Epoch: [0][500/2069]\tBatch Time 0.072 (0.078)\tData Time 0.008 (0.013)\tLoss 8.5959 (10.6459)\t\n",
      "Epoch: [0][550/2069]\tBatch Time 0.063 (0.078)\tData Time 0.001 (0.013)\tLoss 11.3846 (10.4710)\t\n",
      "Epoch: [0][600/2069]\tBatch Time 0.068 (0.078)\tData Time 0.002 (0.013)\tLoss 8.1904 (10.2866)\t\n",
      "Epoch: [0][650/2069]\tBatch Time 0.077 (0.078)\tData Time 0.009 (0.013)\tLoss 7.3193 (10.1415)\t\n",
      "Epoch: [0][700/2069]\tBatch Time 0.067 (0.078)\tData Time 0.002 (0.013)\tLoss 7.0595 (9.9566)\t\n",
      "Epoch: [0][750/2069]\tBatch Time 0.065 (0.078)\tData Time 0.001 (0.013)\tLoss 10.9906 (9.8320)\t\n",
      "Epoch: [0][800/2069]\tBatch Time 0.074 (0.078)\tData Time 0.009 (0.013)\tLoss 8.5235 (9.7360)\t\n",
      "Epoch: [0][850/2069]\tBatch Time 0.072 (0.078)\tData Time 0.009 (0.013)\tLoss 13.6133 (9.6314)\t\n",
      "Epoch: [0][900/2069]\tBatch Time 0.113 (0.078)\tData Time 0.048 (0.013)\tLoss 6.8193 (9.5663)\t\n",
      "Epoch: [0][950/2069]\tBatch Time 0.078 (0.078)\tData Time 0.008 (0.013)\tLoss 7.3524 (9.4576)\t\n",
      "Epoch: [0][1000/2069]\tBatch Time 0.097 (0.078)\tData Time 0.032 (0.013)\tLoss 17.1591 (9.3583)\t\n",
      "Epoch: [0][1050/2069]\tBatch Time 0.132 (0.078)\tData Time 0.058 (0.013)\tLoss 5.7842 (9.2580)\t\n",
      "Epoch: [0][1100/2069]\tBatch Time 0.081 (0.078)\tData Time 0.013 (0.013)\tLoss 9.7730 (9.1795)\t\n",
      "Epoch: [0][1150/2069]\tBatch Time 0.072 (0.078)\tData Time 0.008 (0.013)\tLoss 5.6003 (9.0824)\t\n",
      "Epoch: [0][1200/2069]\tBatch Time 0.072 (0.078)\tData Time 0.009 (0.013)\tLoss 8.4396 (8.9955)\t\n",
      "Epoch: [0][1250/2069]\tBatch Time 0.084 (0.078)\tData Time 0.010 (0.013)\tLoss 5.9254 (8.9055)\t\n",
      "Epoch: [0][1300/2069]\tBatch Time 0.064 (0.078)\tData Time 0.001 (0.013)\tLoss 7.8887 (8.8127)\t\n",
      "Epoch: [0][1350/2069]\tBatch Time 0.068 (0.078)\tData Time 0.001 (0.012)\tLoss 5.1976 (8.7231)\t\n",
      "Epoch: [0][1400/2069]\tBatch Time 0.113 (0.078)\tData Time 0.048 (0.012)\tLoss 7.9936 (8.6545)\t\n",
      "Epoch: [0][1450/2069]\tBatch Time 0.074 (0.078)\tData Time 0.007 (0.012)\tLoss 4.5219 (8.5692)\t\n",
      "Epoch: [0][1500/2069]\tBatch Time 0.066 (0.077)\tData Time 0.001 (0.012)\tLoss 8.0750 (8.5039)\t\n",
      "Epoch: [0][1550/2069]\tBatch Time 0.061 (0.077)\tData Time 0.001 (0.012)\tLoss 4.7421 (8.4326)\t\n",
      "Epoch: [0][1600/2069]\tBatch Time 0.080 (0.077)\tData Time 0.023 (0.012)\tLoss 8.3425 (8.3602)\t\n",
      "Epoch: [0][1650/2069]\tBatch Time 0.066 (0.077)\tData Time 0.001 (0.012)\tLoss 5.8719 (8.2882)\t\n",
      "Epoch: [0][1700/2069]\tBatch Time 0.065 (0.078)\tData Time 0.002 (0.012)\tLoss 5.5191 (8.2345)\t\n",
      "Epoch: [0][1750/2069]\tBatch Time 0.085 (0.077)\tData Time 0.018 (0.012)\tLoss 4.2337 (8.1768)\t\n",
      "Epoch: [0][1800/2069]\tBatch Time 0.073 (0.077)\tData Time 0.007 (0.012)\tLoss 4.2130 (8.1209)\t\n",
      "Epoch: [0][1850/2069]\tBatch Time 0.059 (0.077)\tData Time 0.001 (0.012)\tLoss 5.3220 (8.0682)\t\n",
      "Epoch: [0][1900/2069]\tBatch Time 0.069 (0.077)\tData Time 0.002 (0.012)\tLoss 5.3780 (8.0148)\t\n",
      "Epoch: [0][1950/2069]\tBatch Time 0.066 (0.077)\tData Time 0.001 (0.012)\tLoss 6.6463 (7.9674)\t\n",
      "Epoch: [0][2000/2069]\tBatch Time 0.067 (0.077)\tData Time 0.001 (0.012)\tLoss 4.8787 (7.9204)\t\n",
      "Epoch: [0][2050/2069]\tBatch Time 0.068 (0.077)\tData Time 0.001 (0.012)\tLoss 8.7017 (7.8744)\t\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# train을 수행합니다.\n",
    "train(model, dataloader, criterion, optimizer, scheduler, \n",
    "      num_epochs=1, grad_clip=None, print_freq=50, save_name='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### <생각해 봅시다>\n",
    "\n",
    "- Learing Rate을 달리해가며 초기 학습(< 4epoch)을 살펴봅시다. 어떤 경향을 가지고 있나요?\n",
    "- Gradient를 Clip한다는 것은 어떤 의미를 가질까요?\n",
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
