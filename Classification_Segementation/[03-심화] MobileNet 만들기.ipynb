{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [03] COVID Image Classification: MobileNet 구조 만들기\n",
    "\n",
    "본 실습에서는 이미지 분류에서 경량화 모델로 널리 알려진 MobileNet V2를 구현해보겠습니다.\n",
    "\n",
    "논문의 링크는 이곳입니다. (https://arxiv.org/pdf/1801.04381.pdf)\n",
    "\n",
    "구조에 대해서 간단하게 짚어보겠습니다. 아래의 그림들은 모두 위의 논문에서 발췌하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MobileNetV2](./imgs/mobileNetV2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경량화 신경망들의 구조를 뽑아본 것입니다. 여기서 가장 눈여겨 볼 것은 MobileNet과 MobileNetV2입니다.\n",
    "\n",
    "두 신경망의 가장 큰 차이는 `bottleneck` 구조입니다. `Inverted Residual Block`으로 보통 부릅니다.\n",
    "\n",
    "아래는 `MobileNet`에 대한 설명입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overview_mobilenet](./imgs/overview_mobilenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면, MobileNetV2는 기존의 구조에 bottleneck 구조를 더한 아래와 같은 형태입니다.\n",
    "\n",
    "- `1x1` => `3x3` => `1x1`을 이어서 block을 형성한 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bottleneck](./imgs/bottleneck.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것을 기반으로 MobileNetV2는 아래처럼 구조를 만들었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overview](./imgs/overview_mobilenetv2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드는 파이토치의 official 코드를 조금 고친 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.utils import load_state_dict_from_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1, bn_aff = True):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        super(ConvBNReLU, self).__init__(\n",
    "            ?????, # Convolutional Layer\n",
    "            ?????, # Batch Normalization\n",
    "            ?????, # ReLU activation function\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InvertedResidual Block Remind 요약\n",
    "- 기존의 Convolution filter를 두 가지로 분리해서 붙이는 것을 고안한 방법입니다..\n",
    "    1. Depthwise convolution: 3x3 convolution이나 channel마다 계산을 하는 (평면적으로) 함수.\n",
    "    2. Pointwise convolution: 1x1의 original convolution의 형태. 서로 다른 channel들의 값을 고려하는 함수.\n",
    "- 위의 내용에 더해 expansion - convolution - squeeze의 형태로 block이 구성됩니다. (Inverted Residual Block)\n",
    "- 쉽게 이야기하면 아래와 같습니다.\n",
    "    1. 처음 들어온 input의 channel을 확장시키는 pointwise convolution을 통과함.\n",
    "    2. channel의 수가 늘어난 input을 depthwise convolution을 통과함.\n",
    "    3. 다시 channel 수를 줄이는 (squeeze) pointwise convolution을 통과함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio, shortcut, bn_aff):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.shortcut = shortcut\n",
    "        self.bn_aff = bn_aff\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            # pw\n",
    "            layers.append(???????)\n",
    "        layers.extend([\n",
    "            # dw\n",
    "            ?????????,\n",
    "            # pw-linear\n",
    "            ???????????,\n",
    "            ???????????,\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            if self.shortcut:\n",
    "                return ?????????\n",
    "            else:\n",
    "                return self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래는 inverted residual block으로 구성한 network의 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_urls = {\n",
    "    'mobilenet_v2': 'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_classes=1000,\n",
    "                 width_mult=1.0,\n",
    "                 inverted_residual_setting=None,\n",
    "                 round_nearest=8,\n",
    "                 block=None,\n",
    "                 shortcut=True,\n",
    "                 bn_aff=True):\n",
    "        \"\"\"\n",
    "        MobileNet V2 main class\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): Number of classes\n",
    "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
    "            inverted_residual_setting: Network structure\n",
    "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
    "            Set to 1 to turn off rounding\n",
    "            block: Module specifying inverted residual building block for mobilenet\n",
    "\n",
    "        \"\"\"\n",
    "        super(MobileNetV2, self).__init__()\n",
    "\n",
    "        if block is None:\n",
    "            block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        self.bn_aff = bn_aff\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "        if inverted_residual_setting is None:\n",
    "            inverted_residual_setting = [\n",
    "                # t, c, n, s\n",
    "                ?????????,\n",
    "                ?????????,\n",
    "                ?????????,\n",
    "                ?????????,\n",
    "                ?????????,\n",
    "                ?????????,\n",
    "                ?????????,\n",
    "            ]\n",
    "\n",
    "        # only check the first element, assuming user knows t,c,n,s are required\n",
    "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
    "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
    "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
    "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
    "        features = [ConvBNReLU(3, input_channel, stride=2, bn_aff = self.bn_aff)]\n",
    "        \n",
    "        \n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride, expand_ratio=t, shortcut = self.shortcut, bn_aff = self.bn_aff))\n",
    "                input_channel = output_channel\n",
    "                \n",
    "                \n",
    "        # building last several layers\n",
    "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1, bn_aff = self.bn_aff))\n",
    "        \n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # This exists since TorchScript doesn't support inheritance, so the superclass method\n",
    "        # (this one) needs to have a name other than `forward` that can be accessed in a subclass\n",
    "        x = self.features(x)\n",
    "        # Cannot use \"squeeze\" as batch-size can be 1 => must use reshape with x.shape[0]\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, 1).reshape(x.shape[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobilenet_v2(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV2 architecture from\n",
    "    `\"MobileNetV2: Inverted Residuals and Linear Bottlenecks\" <https://arxiv.org/abs/1801.04381>`_.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(**kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['mobilenet_v2'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
