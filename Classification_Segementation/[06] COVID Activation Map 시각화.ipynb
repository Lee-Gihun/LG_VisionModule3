{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [06] COVID Activation Map의 시각화\n",
    "\n",
    "본 실습에서는 학습한 이미지 분류 신경망의 응용 중 하나인 `Activation Map의 시각화`에 대해서 다뤄볼려고 합니다.\n",
    "\n",
    "아래의 자료는 하기에 표기된 저장소의 자료를 기반으로 만들었습니다.\n",
    "\n",
    "- Author:   Kazuto Nakashima\n",
    "- URL:      http://kazuto1011.github.io\n",
    "- Created:  2017-05-26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Map\n",
    "\n",
    "`Activation Map`은 Interpretable Machine Learning에서 많이 사용/언급 되는 기법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-features-prediction-diagram](./imgs/image-features-prediction-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "심층 신경망은 주어진 입력 이미지에 대하여, 사전에 학습된 여러 개의 층들을 통과해 feature extraction을 수행하고 해당되는 feature map들을 뽑아냅니다.\n",
    "\n",
    "그리고 신경망은 그것을 기반으로 하여 예측(prediction)을 합니다.\n",
    "\n",
    "여기서 Activation map을 본다함은, feature map의 연산에 중요하게 관여하는 부분이 원래 이미지의 어디에서 오는지를 본다~ 입니다.\n",
    "\n",
    "즉 feature map의 활성화(activation) 부분을 본다입니다. (feature map이라는 용어는 쉽게 신경망을 통과하면서 중간에 나오는 출력값들이라 생각하시면 됩니다.)\n",
    "\n",
    "하기의 코드들은 Activation Map을 보기위한 방법 중 `Class Activation Map`에 해당됩니다.\n",
    "\n",
    "### Class Activation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![class-activation-mapping](./imgs/class-activation-mapping.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Activation Map은 컨볼루션 layer 상에서 Attribution을 수행하기 때문에 상대적으로 부드러운 Attribution 결과를 보여준다는 특징이 있습니다. (위 그림)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taehyeon/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from collections import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization을 위한 BaseWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _BaseWrapper(object):\n",
    "    def __init__(self, model):\n",
    "        super(_BaseWrapper, self).__init__()\n",
    "        self.device = next(model.parameters()).device\n",
    "        self.model = model\n",
    "        self.handlers = []  # a set of hook function handlers\n",
    "\n",
    "    def _encode_one_hot(self, ids):\n",
    "        one_hot = torch.zeros_like(???????).to(self.device)\n",
    "        one_hot.scatter_(1, ids, 1.0)\n",
    "        return one_hot\n",
    "\n",
    "    def forward(self, image):\n",
    "        self.image_shape = image.shape[2:]\n",
    "        self.logits = ???????\n",
    "        self.probs = ???????\n",
    "        return self.probs.sort(dim=1, descending=True)  # ordered results\n",
    "\n",
    "    def backward(self, ids):\n",
    "        \"\"\"\n",
    "        Class-specific backpropagation\n",
    "        \"\"\"\n",
    "        one_hot = self._encode_one_hot(ids)\n",
    "        self.model.zero_grad()\n",
    "        self.logits.backward(gradient=one_hot, retain_graph=True)\n",
    "\n",
    "    def generate(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def remove_hook(self):\n",
    "        \"\"\"\n",
    "        Remove all the forward/backward hook functions\n",
    "        \"\"\"\n",
    "        for handle in self.handlers:\n",
    "            handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackPropagation\n",
    "\n",
    "이미지에 걸리는 Gradient를 보고 다른 색이 칠해져 있는 부분이 activation이 강하다고 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackPropagation(_BaseWrapper):\n",
    "    def forward(self, image):\n",
    "        self.image = ??????????\n",
    "        return super(BackPropagation, self).forward(self.image)\n",
    "\n",
    "    def generate(self):\n",
    "        gradient = self.image.grad.clone()\n",
    "        \n",
    "        ### make zero_grad\n",
    "        ????????????\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GuidedBackPropagation\n",
    "\n",
    "위와 같지만 다른 점이 있다면, relu outputs이 양수인 부분에만 gradients를 구하는 방식입니다.\n",
    "\n",
    "$$ gradients = \\frac{\\partial y_{label}}{\\partial\\, last\\, conv\\, layer} (gradients>0) \\,\\& \\,(relu\\,output>0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuidedBackPropagation(BackPropagation):\n",
    "    \"\"\"\n",
    "    \"Striving for Simplicity: the All Convolutional Net\"\n",
    "    https://arxiv.org/pdf/1412.6806.pdf\n",
    "    Look at Figure 1 on page 8.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super(GuidedBackPropagation, self).__init__(model)\n",
    "\n",
    "        def backward_hook(module, grad_in, grad_out):\n",
    "            # Cut off negative gradients\n",
    "            if isinstance(module, nn.ReLU):\n",
    "                return (????????????)\n",
    "\n",
    "        for module in self.model.named_modules():\n",
    "            self.handlers.append(module[1].register_backward_hook(backward_hook))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grad-CAM(Gradient-weighted CAM)은 CAM을 구할 때,`예측 이미지안의 중요한 부분을 강조하는 대략적인 지역 맵을 생산하기위한 마지막 컨볼루션 층으로 흘러가는`,\n",
    "`타겟 클래스(캡션, 마스크도 가능)에 대한` gradient를 이용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gradcam_overview](./imgs/gradcam_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wordbe.tistory.com/entry/Grad-CAMGradient-weighted-Class-Activation-Mapping 의 자료를 참고했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grad_cam_1](./imgs/grad_cam_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification 문제에서 예를 들어보면, Grad-CAM( width=u, height=v 인 특정 클래스 c에 대한 이미지 )을 얻기위해\n",
    "\n",
    "backprop을 통한 gradient 값들을 얻습니다.\n",
    "\n",
    "이를 위해 softmax 전 단계의 각 클래스에 대한 y score를, k번째 특징 맵 A에 대한 gradient를 얻습니다.\n",
    "\n",
    "여기에 GAP(Global Average Pooling) 값과 곱하여 뉴런 중요도 가중치(neuron importance weight)인 $$\\alpha_k^c$$\n",
    "\n",
    "를 얻습니다.\n",
    "\n",
    "![grad_cam_2](./imgs/grad_cam_2.png)\n",
    "\n",
    "이렇게 얻은 가중치는 타켓 클래스 c에 대한 특징 맵 k의 중요도를 잡을 수 있는데요,\n",
    "\n",
    "k개의 각 뉴런 중요도 가중치와, 각 특징 맵을 곱하고 더하여 (linear combination) ReLU를 덮어씌웁니다.\n",
    "\n",
    " \n",
    "\n",
    "클래스의 interest에서 양의 값의 영향에 관심이 있기 때문에 렐루를 붙였습니다.\n",
    "\n",
    "그리고 결과적으로 더 좋은 CAM을 만들었음을 실험으로 밝혔습니다.\n",
    "\n",
    "### Grad-CAM as a generalization to CAM\n",
    "\n",
    "![grad_cam_3](./imgs/grad_cam_3.png)\n",
    "\n",
    "각 클래스에 대한 스코어 S를 얻기 위해 다음과 같은 식을 이용할 수 있습니다.\n",
    "\n",
    "![grad_cam_4](./imgs/grad_cam_4.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM(_BaseWrapper):\n",
    "    \"\"\"\n",
    "    \"Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization\"\n",
    "    https://arxiv.org/pdf/1610.02391.pdf\n",
    "    Look at Figure 2 on page 4\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, candidate_layers=None):\n",
    "        super(GradCAM, self).__init__(model)\n",
    "        self.fmap_pool = {}\n",
    "        self.grad_pool = {}\n",
    "        self.candidate_layers = candidate_layers  # list\n",
    "\n",
    "        def save_fmaps(key):\n",
    "            def forward_hook(module, input, output):\n",
    "                self.fmap_pool[key] = output.detach()\n",
    "\n",
    "            return forward_hook\n",
    "\n",
    "        def save_grads(key):\n",
    "            def backward_hook(module, grad_in, grad_out):\n",
    "                self.grad_pool[key] = grad_out[0].detach()\n",
    "\n",
    "            return backward_hook\n",
    "\n",
    "        # If any candidates are not specified, the hook is registered to all the layers.\n",
    "        for name, module in self.model.named_modules():\n",
    "            if self.candidate_layers is None or name in self.candidate_layers:\n",
    "                self.handlers.append(module.register_forward_hook(save_fmaps(name)))\n",
    "                self.handlers.append(module.register_backward_hook(save_grads(name)))\n",
    "\n",
    "    def _find(self, pool, target_layer):\n",
    "        if target_layer in pool.keys():\n",
    "            return pool[target_layer]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layer name: {}\".format(target_layer))\n",
    "\n",
    "    def generate(self, target_layer):\n",
    "        fmaps = self._find(self.fmap_pool, target_layer)\n",
    "        grads = self._find(self.grad_pool, target_layer)\n",
    "        weights = F.adaptive_avg_pool2d(grads, 1)\n",
    "\n",
    "        gcam = torch.mul(fmaps, weights).sum(dim=1, keepdim=True)\n",
    "        gcam = F.relu(gcam)\n",
    "        gcam = F.interpolate(\n",
    "            gcam, self.image_shape, mode=\"bilinear\", align_corners=False\n",
    "        )\n",
    "\n",
    "        B, C, H, W = gcam.shape\n",
    "        gcam = gcam.view(B, -1)\n",
    "        gcam -= gcam.min(dim=1, keepdim=True)[0]\n",
    "        gcam /= gcam.max(dim=1, keepdim=True)[0]\n",
    "        gcam = gcam.view(B, C, H, W)\n",
    "\n",
    "        return gcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### <생각해 봅시다>\n",
    "\n",
    "- Grad-CAM의 gradient는 어디서 얻어 오는 것이 적절할까요?\n",
    "\n",
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
